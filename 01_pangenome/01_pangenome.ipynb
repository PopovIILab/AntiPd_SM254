{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CHAPTER 1. Pangenome analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from Bio import Entrez, SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study `PanACoTA` software will be used for Pangenome analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir pangenome/\n",
    "mkdir pangenome/data/\n",
    "mkdir pangenome/Annotation/\n",
    "mkdir pangenome/Annotation/Genes/\n",
    "mkdir pangenome/Annotation/Proteins/\n",
    "mkdir pangenome/Annotation/Proteins_classic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will need the list of accession numbers of _Streptomyces albidoflavus_ complete genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! esearch -db nucleotide \\\n",
    "    -query '(\"Streptomyces albidoflavus\"[Organism] OR \"Streptomyces albidoflavus\"[All Fields]) AND \"complete\"[All Fields] AND (bacteria[filter] AND biomol_genomic[PROP] AND refseq[filter] AND is_nuccore[filter] AND (\"5000000\"[SLEN] : \"20000000\"[SLEN]))' \\\n",
    "    | efetch -format acc > pangenome/data/accession_numbers.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will download us everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(email, file_path, output_dir, format, extension):\n",
    "    Entrez.email = email\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Read accession numbers from file\n",
    "    with open(file_path, \"r\") as file:\n",
    "        accession_numbers = file.read().split()\n",
    "\n",
    "    def download_sequence(accession):\n",
    "        \"\"\"Fetches a single sequence from NCBI and saves it as a FASTA file.\"\"\"\n",
    "        try:\n",
    "            handle = Entrez.efetch(\n",
    "                db=\"nucleotide\", id=accession, rettype=format, retmode=\"text\"\n",
    "            )\n",
    "            records = list(SeqIO.parse(handle, \"fasta\"))  # Use parse() instead of read()\n",
    "            handle.close()\n",
    "\n",
    "            if records:\n",
    "                output_path = os.path.join(output_dir, f\"{accession.split('.')[0]}.{extension}\")\n",
    "                SeqIO.write(records, output_path, \"fasta\")\n",
    "                print(f\"Downloaded: {accession}\")\n",
    "            else:\n",
    "                print(f\"No CDS found for {accession}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {accession}: {e}\")\n",
    "\n",
    "    # Download sequences for each accession number\n",
    "    for accession in accession_numbers:\n",
    "        download_sequence(accession)\n",
    "\n",
    "    print(\"All downloads completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"ivpopov@donstu.ru\"\n",
    "accession_numbers = \"pangenome/data/accession_numbers.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sequences(email,\n",
    "              accession_numbers,\n",
    "              \"pangenome/Annotation/Genes\",\n",
    "              format = \"fasta_cds_na\",\n",
    "              extension = \"gen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download proteomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sequences(email,\n",
    "              accession_numbers,\n",
    "              \"pangenome/Annotation/Proteins_classic\",\n",
    "              format = \"fasta_cds_aa\",\n",
    "              extension = \"prt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to rename downloaded proteomes to make them face the requirements of `PanACoTA` input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for file in pangenome/Annotation/Proteins_classic/*.prt; do \n",
    "    awk '\n",
    "    {\n",
    "        if ($0 ~ /^>/) {\n",
    "            line = $0\n",
    "            sub(/^>lcl\\|/, \">\", line)                       # Step 1: Remove \"lcl|\"\n",
    "            split(line, a, \"_prot_\")                        # Step 2: Split into before/after \"_prot_\"\n",
    "            id = a[1]                                       # Take the part before _prot_\n",
    "            sub(/\\.[0-9]+$/, \"\", id)                        # Step 3: Remove .1/.11/.111 at end of ID\n",
    "\n",
    "            # Now process the part after _prot_ (if exists)\n",
    "            if (length(a) > 1) {\n",
    "                split(a[2], b, \"_\")                         # Split second part by \"_\"\n",
    "                seq = b[2]                                  # Take second chunk: \"RT032785929\" or similar\n",
    "                gsub(/[^0-9]/, \"\", seq)                     # Step 5: Remove letters, keep numbers only\n",
    "                print id \"_\" seq\n",
    "            } else {\n",
    "                print id\n",
    "            }\n",
    "        } else {\n",
    "            print\n",
    "        }\n",
    "    }' \"$file\" > pangenome/Annotation/Proteins/$(basename \"$file\")\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the renaming from proteomes to genomes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "proteins_dir = \"pangenome/Annotation/Proteins\"\n",
    "genes_dir = \"pangenome/Annotation/Genes\"\n",
    "\n",
    "# Ensure Genes directory exists\n",
    "if not os.path.exists(genes_dir):\n",
    "    print(\"Genes directory does not exist.\")\n",
    "    exit(1)\n",
    "\n",
    "# Function to extract FASTA sequences\n",
    "def read_fasta(file_path):\n",
    "    sequences = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        seq = []\n",
    "        header = None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if header:\n",
    "                    sequences.append((header, \"\\n\".join(seq)))\n",
    "                header = line  # Store new header\n",
    "                seq = []\n",
    "            else:\n",
    "                seq.append(line)\n",
    "        if header:\n",
    "            sequences.append((header, \"\\n\".join(seq)))  # Append last sequence\n",
    "    return sequences\n",
    "\n",
    "# Function to write updated FASTA sequences\n",
    "def write_fasta(file_path, sequences):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for header, seq in sequences:\n",
    "            f.write(f\"{header}\\n{seq}\\n\")\n",
    "\n",
    "# Process all .prt files in Proteins directory\n",
    "for prt_file in os.listdir(proteins_dir):\n",
    "    if prt_file.endswith(\".prt\"):\n",
    "        # Get corresponding .gen file\n",
    "        base_name = os.path.splitext(prt_file)[0]  # Remove .prt extension\n",
    "        gen_file = f\"{base_name}.gen\"\n",
    "        \n",
    "        prt_path = os.path.join(proteins_dir, prt_file)\n",
    "        gen_path = os.path.join(genes_dir, gen_file)\n",
    "\n",
    "        # Check if corresponding .gen file exists\n",
    "        if not os.path.exists(gen_path):\n",
    "            print(f\"Skipping {gen_file} (not found in Genes directory)\")\n",
    "            continue\n",
    "\n",
    "        # Read sequences from .prt and .gen files\n",
    "        prt_seqs = read_fasta(prt_path)\n",
    "        gen_seqs = read_fasta(gen_path)\n",
    "\n",
    "        # Ensure both files have the same number of sequences\n",
    "        if len(prt_seqs) != len(gen_seqs):\n",
    "            print(f\"Skipping {gen_file} (mismatch: {len(prt_seqs)} protein seqs vs {len(gen_seqs)} gene seqs)\")\n",
    "            continue\n",
    "\n",
    "        # Replace headers in .gen file\n",
    "        updated_gen_seqs = [(prt_seqs[i][0], gen_seqs[i][1]) for i in range(len(gen_seqs))]\n",
    "\n",
    "        # Write updated .gen file\n",
    "        write_fasta(gen_path, updated_gen_seqs)\n",
    "        print(f\"Updated {gen_file} with new headers from {prt_file}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a list file with the proteomes to build the pangenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls pangenome/Annotation/Proteins/*.prt | sed 's|pangenome/Annotation/Proteins/||' | sed 's/\\.prt$//' >\\\n",
    "    pangenome/Annotation/LSTINFO-.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we must create a merged proteomes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pangenome/Annotation/Proteins/* > pangenome/Annotation/Proteins/StAl.All.prt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now let's construct a pangenome with the proteins identity setting = `0.9` (90%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  * [2025-04-29 15:50:39] : INFO \u001b[0m PanACoTA version 1.4.0\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:50:39] : INFO \u001b[0m Command used\n",
      " \t > PanACoTA pangenome -l pangenome/Annotation/LSTINFO-.lst -n StAl -d pangenome/Annotation/Proteins/ -o pangenome/Pangenome -i 0.9\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:50:39] : INFO \u001b[0m Will run MMseqs2 with:\n",
      "\t- minimum sequence identity = 90.0%\n",
      "\t- cluster mode 1\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:50:39] : INFO \u001b[0m Creating database\u001b[0m\n",
      "|       ◐              |  -  Elapsed Time: 0:00:00\n",
      "\u001b[32m  * [2025-04-29 15:50:40] : INFO \u001b[0m Clustering proteins...\u001b[0m\n",
      "|        ◐             |  -  Elapsed Time: 0:04:18\n",
      "\u001b[32m  * [2025-04-29 15:54:59] : INFO \u001b[0m Converting mmseqs results to pangenome file\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:54:59] : INFO \u001b[0m Pangenome has 12027 families.\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:54:59] : INFO \u001b[0m Retrieving information from pan families\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:54:59] : INFO \u001b[0m Generating qualitative and quantitative matrix, and summary file\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:54:59] : INFO \u001b[0m DONE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! PanACoTA pangenome -l pangenome/Annotation/LSTINFO-.lst -n StAl -d pangenome/Annotation/Proteins/ -o pangenome/Pangenome -i 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will calculate the pangenome composition for:<br>\n",
    "- _Streptomyces albidoflavus_<br>\n",
    "- _Streptomyces albidoflavus_ SM254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pangenome(input_path: str, output_path: str, target_prefix: str = None, total_genomes: int = 34) -> None:\n",
    "    \"\"\"Analyze pangenome gene clusters and categorize them by presence across genomes.\"\"\"\n",
    "    counts = {\n",
    "        'Core': 0,\n",
    "        'Soft-core': 0,\n",
    "        'Shell': 0,\n",
    "        'Cloud': 0\n",
    "    }\n",
    "\n",
    "    with open(input_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "\n",
    "            elements = parts[1:]\n",
    "\n",
    "            # If filtering by prefix, check and ensure no duplicates\n",
    "            if target_prefix:\n",
    "                if not any(p.startswith(target_prefix) for p in elements):\n",
    "                    continue\n",
    "                if len(set(elements)) != len(elements):\n",
    "                    continue\n",
    "            else:\n",
    "                if len(set(elements)) != len(elements):\n",
    "                    continue\n",
    "\n",
    "            n = len(elements)\n",
    "\n",
    "            if n == total_genomes:\n",
    "                counts['Core'] += 1\n",
    "            elif n in {total_genomes - 1, total_genomes - 2}:\n",
    "                counts['Soft-core'] += 1\n",
    "            elif 1 < n < total_genomes - 2:\n",
    "                counts['Shell'] += 1\n",
    "            elif n <= 1:\n",
    "                counts['Cloud'] += 1\n",
    "\n",
    "    with open(output_path, 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file, delimiter='\\t')\n",
    "        writer.writerow(['Category', 'Count'])\n",
    "        for category, count in counts.items():\n",
    "            writer.writerow([category, count])\n",
    "\n",
    "    print(\"Analysis complete. Results saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to: pangenome/sm254_pangenome.tsv\n",
      "Analysis complete. Results saved to: pangenome/StAl_pangenome.tsv\n"
     ]
    }
   ],
   "source": [
    "# Run for SM254 (with filtering for NZ_CP014485_)\n",
    "analyze_pangenome(\n",
    "    input_path='pangenome/Pangenome/PanGenome-StAl.All.prt-clust-0.9-mode1.lst',\n",
    "    output_path='pangenome/sm254_pangenome.tsv',\n",
    "    target_prefix='NZ_CP014485_'\n",
    ")\n",
    "\n",
    "# Run for all StAl (no filtering)\n",
    "analyze_pangenome(\n",
    "    input_path='pangenome/Pangenome/PanGenome-StAl.All.prt-clust-0.9-mode1.lst',\n",
    "    output_path='pangenome/StAl_pangenome.tsv',\n",
    "    target_prefix=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now please proceed to the `02_pangenome_visualization.R` and run the analysis there. Then come back!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now run `PanACoTA`'s `corepers` module to extract core genes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m PanACoTA version 1.4.0\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m Command used\n",
      " \t > PanACoTA corepers -p pangenome/Pangenome/PanGenome-StAl.All.prt-clust-0.9-mode1.lst -o pangenome/Coregenome -t 1\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m Will generate a CoreGenome.\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m Retrieving info from binary file\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m Generating Persistent genome of a dataset containing 34 genomes\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m The core genome contains 3867 families, each one having exactly 34 members, from the 34 different genomes.\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 15:55:43] : INFO \u001b[0m Persistent genome step done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! PanACoTA corepers -p pangenome/Pangenome/PanGenome-StAl.All.prt-clust-0.9-mode1.lst -o pangenome/Coregenome -t 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to perform multiple sequences alignment of 3867 core genes<br>\n",
    ">Lifehack: instead of running `MAFFT` by ourselves, we can still run `PanACoTA`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  * [2025-04-29 16:03:15] : INFO \u001b[0m PanACoTA version 1.4.0\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 16:03:15] : INFO \u001b[0m Command used\n",
      " \t > PanACoTA align -c pangenome/Coregenome/PersGenome_PanGenome-StAl.All.prt-clust-0.9-mode1.lst-all_1.0.lst -l pangenome/Annotation/LSTINFO-.lst -n StAl -d pangenome/Annotation/ -o pangenome/Alignment\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 16:03:15] : INFO \u001b[0m Found 34 genomes.\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 16:03:15] : INFO \u001b[0m Reading PersGenome and constructing lists of missing genomes in each family.\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 16:03:15] : INFO \u001b[0m Getting all persistent proteins and classify by strain.\u001b[0m\n",
      "\u001b[32m  * [2025-04-29 16:03:16] : INFO \u001b[0m Extracting proteins and genes from all genomes\u001b[0m\n",
      "Extraction:████████████████ 34/34 (100%) - Elapsed Time: 0:00:18 Time:  0:00:18\n",
      "\u001b[32m  * [2025-04-29 16:03:34] : INFO \u001b[0m Starting alignment of all families: protein alignment, back-translation to nucleotides, and add missing genomes in the family\u001b[0m\n",
      "Alignment: ████████████████████████ 3867/3867 (100%) - Elapsed Time: 1:17:28 - \u001b[32m  * [2025-04-29 17:21:03] : INFO \u001b[0m Concatenating all nucl alignment files\u001b[0m\n",
      "Concatenation: ███████████████████████ 3867/3867 (100%) - Elapsed Time: 0:00:01\n",
      "\u001b[32m  * [2025-04-29 17:21:04] : INFO \u001b[0m Grouping nucleic alignments per genome\u001b[0m\n",
      "|           ◐          |  -  Elapsed Time: 0:00:01\n",
      "\u001b[32m  * [2025-04-29 17:21:05] : INFO \u001b[0m END\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! PanACoTA align -c pangenome/Coregenome/PersGenome_PanGenome-StAl.All.prt-clust-0.9-mode1.lst-all_1.0.lst\\\n",
    "    -l pangenome/Annotation/LSTINFO-.lst -n StAl -d pangenome/Annotation/ -o pangenome/Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got the MSAs! Now what? `MODELFINDER`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store `ModelFinder` log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pangenome/model-finder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run a `ModelFinder` on concatenated MSA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "iqtree2 -m MFP -s pangenome/Alignment/Phylo-StAl/StAl.nucl.grp.aln --prefix pangenome/model-finder/StAl -T AUTO -safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit model according to BIC: TVM+F+R5\n",
      "\n",
      "List of models sorted by BIC scores: \n",
      "\n",
      "Model                  LogL         AIC      w-AIC        AICc     w-AICc         BIC      w-BIC\n",
      "TVM+F+R5        -7526742.522 15053645.044 +    0.554 15053645.047 +    0.554 15054697.419 +    0.999\n"
     ]
    }
   ],
   "source": [
    "! head -42 pangenome/model-finder/StAl.iqtree | tail -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last... We have the best fit model... It's time to launch `IQ-TREE`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a directory to store the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pangenome/tree/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run an `IQ-TREE` on concatenated MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "iqtree2 -s pangenome/Alignment/Phylo-StAl/StAl.nucl.grp.aln -m TVM+F+R5 -pre pangenome/tree/StAl_ufb -bb 10000 -nt AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually that's all!<br>\n",
    "But now we'll fetch metadata on _Streptomyces albidoflavus_ from NCBI RefSeq<br>\n",
    "It will be used to annotate the trees in `ggtree`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a directory where to store metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir metadata/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fetch metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata retrieval complete.\n",
      "File saved to metadata/metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "! Phyloki --fetch_metadata -email ivpopov@donstu.ru -i pangenome/data/accession_numbers.txt -o metadata/metadata.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last thing to do — trim versions out of accession numbers (to make metadata meet the corresponding samples in the tree!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('metadata/metadata.tsv', sep='\\t')\n",
    "df[\"AN\"] = df[\"AN\"].str.split('.').str[0]\n",
    "df.to_csv('metadata/welldone_metadata.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for pangenome analysis! Please proceed to the `03_ggtree_journal` for further analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then please welcome to `04_ANI.ipynb` for Average Nucleotide Identity analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
